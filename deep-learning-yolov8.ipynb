{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2840219,"sourceType":"datasetVersion","datasetId":1724942}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/xmortian/deep-learning-yolov8?scriptVersionId=260448525\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-06T08:08:27.233036Z","iopub.execute_input":"2025-09-06T08:08:27.23331Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install ultralytics opencv-python matplotlib numpy tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.idle":"2025-09-06T08:13:28.352985Z","shell.execute_reply.started":"2025-09-06T08:11:50.908229Z","shell.execute_reply":"2025-09-06T08:13:28.351672Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ultralytics import YOLO\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T08:13:28.354751Z","iopub.execute_input":"2025-09-06T08:13:28.355232Z","iopub.status.idle":"2025-09-06T08:13:32.363884Z","shell.execute_reply.started":"2025-09-06T08:13:28.355175Z","shell.execute_reply":"2025-09-06T08:13:32.363107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load YOLOv8 segmentation model (nano for speed)\nmodel = YOLO(\"yolov8n-seg.pt\")  # or yolov8s-seg.pt for better accuracy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T08:13:32.364879Z","iopub.execute_input":"2025-09-06T08:13:32.365377Z","iopub.status.idle":"2025-09-06T08:13:32.805686Z","shell.execute_reply.started":"2025-09-06T08:13:32.365348Z","shell.execute_reply":"2025-09-06T08:13:32.804736Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Classical PipeLine\ndef classical_lane_detection(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    blur = cv2.GaussianBlur(gray, (5,5), 0)\n    edges = cv2.Canny(blur, 50, 150)\n\n    mask = np.zeros_like(edges)\n    height = image.shape[0]\n    polygons = np.array([[(200, height), (1100, height), (550, 250)]])\n    cv2.fillPoly(mask, polygons, 255)\n    masked = cv2.bitwise_and(edges, mask)\n\n    lines = cv2.HoughLinesP(masked, 2, np.pi/180, 100, np.array([]),\n                            minLineLength=40, maxLineGap=5)\n\n    line_image = np.zeros_like(image)\n    if lines is not None:\n        for line in lines:\n            x1, y1, x2, y2 = line[0]\n            cv2.line(line_image, (x1, y1), (x2, y2), (0, 255, 0), 10)\n\n    combined = cv2.addWeighted(image, 0.8, line_image, 1, 1)\n    return combined\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T08:13:32.808172Z","iopub.execute_input":"2025-09-06T08:13:32.808453Z","iopub.status.idle":"2025-09-06T08:13:32.816204Z","shell.execute_reply.started":"2025-09-06T08:13:32.808431Z","shell.execute_reply":"2025-09-06T08:13:32.815288Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Path to your TuSimple dataset\ndataset_path = \"/kaggle/input/tusimple/TUSimple\"\n\n# Pick a sample test image\ntest_img_path = os.path.join(dataset_path, \"/kaggle/input/tusimple/TUSimple/test_set/clips/0530/1492630582174670101_0/20.jpg\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T08:13:32.817146Z","iopub.execute_input":"2025-09-06T08:13:32.817447Z","iopub.status.idle":"2025-09-06T08:13:32.837329Z","shell.execute_reply.started":"2025-09-06T08:13:32.817428Z","shell.execute_reply":"2025-09-06T08:13:32.836511Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" #STEP 3\ntusimple_root = \"/kaggle/input/tusimple/TUSimple\"\ntrain_clips = os.path.join(tusimple_root, \"train_set/clips\")\ntrain_labels_1 = os.path.join(tusimple_root, \"train_set/label_data_0313.json\")\ntrain_labels_2 = os.path.join(tusimple_root, \"train_set/label_data_0531.json\")\ntrain_labels_3 = os.path.join(tusimple_root, \"train_set/label_data_0601.json\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T08:13:35.927866Z","iopub.execute_input":"2025-09-06T08:13:35.928131Z","iopub.status.idle":"2025-09-06T08:13:35.933667Z","shell.execute_reply.started":"2025-09-06T08:13:35.928111Z","shell.execute_reply":"2025-09-06T08:13:35.932621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_path = \"/kaggle/working/tusimple_yolo\"\nimg_train = os.path.join(base_path, \"images/train\")\nimg_val = os.path.join(base_path, \"images/val\")\nlbl_train = os.path.join(base_path, \"labels/train\")\nlbl_val = os.path.join(base_path, \"labels/val\")\n\nfor p in [img_train, img_val, lbl_train, lbl_val]:\n    os.makedirs(p, exist_ok=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T08:13:35.934601Z","iopub.execute_input":"2025-09-06T08:13:35.934946Z","iopub.status.idle":"2025-09-06T08:13:35.947509Z","shell.execute_reply.started":"2025-09-06T08:13:35.934925Z","shell.execute_reply":"2025-09-06T08:13:35.946794Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport cv2\nimport shutil\nfrom tqdm import tqdm\n\ndef convert_json_to_yolo(json_path, clips_root, images_out, labels_out):\n    with open(json_path, \"r\") as f:\n        for line in tqdm(f, desc=f\"Processing {os.path.basename(json_path)}\"):\n            data = json.loads(line)\n            img_rel = data[\"raw_file\"]  # e.g., clips/0531/123/20.jpg\n            img_path = os.path.join(clips_root, img_rel.replace(\"clips/\", \"\"))\n            \n            # Skip missing images safely\n            if not os.path.exists(img_path):\n                continue\n            \n            # Copy image into YOLO dataset\n            img_name = os.path.basename(img_path)\n            save_img_path = os.path.join(images_out, img_name)\n            shutil.copy(img_path, save_img_path)\n            \n            # Get image size\n            image = cv2.imread(img_path)\n            height, width = image.shape[:2]\n            \n            # Create YOLO segmentation label\n            label_path = os.path.join(labels_out, img_name.replace(\".jpg\", \".txt\"))\n            with open(label_path, \"w\") as lf:\n                for lane in data[\"lanes\"]:\n                    points = []\n                    for x, y in zip(lane, data[\"h_samples\"]):\n                        if x > 0:  # valid point\n                            points.append(f\"{x/width} {y/height}\")\n                    if points:\n                        lf.write(f\"0 {' '.join(points)}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T08:13:35.948489Z","iopub.execute_input":"2025-09-06T08:13:35.948776Z","iopub.status.idle":"2025-09-06T08:13:35.968069Z","shell.execute_reply.started":"2025-09-06T08:13:35.948747Z","shell.execute_reply":"2025-09-06T08:13:35.967217Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport cv2\nimport numpy as np\nimport shutil\nfrom tqdm import tqdm\n\n# Paths\ntusimple_root = \"/kaggle/input/tusimple/TUSimple\"\nclips_root = os.path.join(tusimple_root, \"train_set/clips\")\n\n# YOLO-formatted dataset folder\nbase_path = \"/kaggle/working/tusimple_yolo\"\nimg_train = os.path.join(base_path, \"images/train\")\nlbl_train = os.path.join(base_path, \"labels/train\")\nos.makedirs(img_train, exist_ok=True)\nos.makedirs(lbl_train, exist_ok=True)\n\n# Helper function: Convert TuSimple JSON → YOLO segmentation masks\ndef create_lane_masks(json_path, clips_root, img_out, lbl_out):\n    with open(json_path, \"r\") as f:\n        for line in tqdm(f, desc=f\"Processing {os.path.basename(json_path)}\"):\n            data = json.loads(line)\n            img_rel = data[\"raw_file\"]\n            img_path = os.path.join(clips_root, img_rel.replace(\"clips/\", \"\"))\n\n            # Skip missing images safely\n            if not os.path.exists(img_path):\n                continue\n\n            # Read original image\n            image = cv2.imread(img_path)\n            height, width = image.shape[:2]\n\n            # Create a blank black mask\n            mask = np.zeros((height, width), dtype=np.uint8)\n\n            # Draw lanes on mask\n            for lane in data[\"lanes\"]:\n                pts = []\n                for x, y in zip(lane, data[\"h_samples\"]):\n                    if x > 0:  # valid point\n                        pts.append((x, y))\n                if len(pts) > 1:\n                    pts = np.array(pts, np.int32).reshape((-1, 1, 2))\n                    cv2.polylines(mask, [pts], isClosed=False, color=255, thickness=8)\n\n            # Save image\n            img_name = os.path.basename(img_path)\n            save_img_path = os.path.join(img_out, img_name)\n            shutil.copy(img_path, save_img_path)\n\n            # Convert mask into YOLO segmentation format\n            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n            label_path = os.path.join(lbl_out, img_name.replace(\".jpg\", \".txt\"))\n            with open(label_path, \"w\") as lf:\n                for cnt in contours:\n                    if len(cnt) >= 3:  # valid polygon\n                        norm_points = []\n                        for p in cnt:\n                            x, y = p[0]\n                            norm_points.append(f\"{x/width} {y/height}\")\n                        lf.write(f\"0 \" + \" \".join(norm_points) + \"\\n\")\n\n# Process all TuSimple training JSONs\ntrain_labels = [\n    os.path.join(tusimple_root, \"train_set/label_data_0313.json\"),\n    os.path.join(tusimple_root, \"train_set/label_data_0531.json\"),\n    os.path.join(tusimple_root, \"train_set/label_data_0601.json\")\n]\n\nfor json_file in train_labels:\n    create_lane_masks(json_file, clips_root, img_train, lbl_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T08:43:12.837305Z","iopub.execute_input":"2025-09-06T08:43:12.837641Z","iopub.status.idle":"2025-09-06T08:44:52.510786Z","shell.execute_reply.started":"2025-09-06T08:43:12.837619Z","shell.execute_reply":"2025-09-06T08:44:52.509832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/tusimple.yaml\npath: /kaggle/working/tusimple_yolo\n\ntrain: images/train\nval: images/train   # We'll split later if needed\n\nnames:\n  0: lane\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T08:46:11.993084Z","iopub.execute_input":"2025-09-06T08:46:11.993423Z","iopub.status.idle":"2025-09-06T08:46:11.999291Z","shell.execute_reply.started":"2025-09-06T08:46:11.9934Z","shell.execute_reply":"2025-09-06T08:46:11.998458Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = YOLO(\"yolov8s-seg.pt\")\nresults = model.train(\n    data=\"/kaggle/working/tusimple.yaml\",\n    epochs=150, # You can keep this high, but patience will stop it early\n    imgsz=640,\n    batch=8,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T10:37:42.637402Z","iopub.execute_input":"2025-09-06T10:37:42.638288Z","iopub.status.idle":"2025-09-06T10:45:36.73811Z","shell.execute_reply.started":"2025-09-06T10:37:42.638256Z","shell.execute_reply":"2025-09-06T10:45:36.737247Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Test image path\ntest_img = os.path.join(\n    tusimple_root,\n    \"/kaggle/input/tusimple/TUSimple/train_set/clips/0531/1492626287507231547/1.jpg\"\n)\n\n# Predict lane segmentation\nresult = model.predict(source=test_img)\n\n# Show YOLO segmentation result\nplt.figure(figsize=(10, 6))\nplt.imshow(result[0].plot())\nplt.axis(\"off\")\nplt.title(\"YOLOv8 Lane Segmentation\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T11:10:13.725421Z","iopub.execute_input":"2025-09-06T11:10:13.726411Z","iopub.status.idle":"2025-09-06T11:10:14.758468Z","shell.execute_reply.started":"2025-09-06T11:10:13.726381Z","shell.execute_reply":"2025-09-06T11:10:14.757281Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Test image path\ntest_img = os.path.join(\n    tusimple_root,\n    \"/kaggle/input/tusimple/TUSimple/test_set/clips/0530/1492630582174670101_0/20.jpg\"\n)\n\n# Predict lane segmentation\nresult = model.predict(source=test_img)\n\n# Show YOLO segmentation result\nplt.figure(figsize=(10, 6))\nplt.imshow(result[0].plot())\nplt.axis(\"off\")\nplt.title(\"YOLOv8 Lane Segmentation\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T11:10:26.211086Z","iopub.execute_input":"2025-09-06T11:10:26.211464Z","iopub.status.idle":"2025-09-06T11:10:27.069769Z","shell.execute_reply.started":"2025-09-06T11:10:26.211437Z","shell.execute_reply":"2025-09-06T11:10:27.068837Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nfrom ultralytics import YOLO\nfrom IPython.display import Video\n\n# Paths\ntusimple_root = \"/kaggle/input/tusimple/TUSimple\"\nclip_path = os.path.join(tusimple_root, \"train_set/clips/0531/1492626287507231547\")\n\n# 1️⃣ Create a video from frames\nvideo_path = \"/kaggle/working/sample_clip.mp4\"\nframes = sorted([f for f in os.listdir(clip_path) if f.endswith(\".jpg\")])\n\n# Read first frame to get video dimensions\nfirst_frame = cv2.imread(os.path.join(clip_path, frames[0]))\nheight, width, _ = first_frame.shape\n\n# Create video writer using MP4 codec\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(video_path, fourcc, 30, (width, height))\n\n# Write all frames into video\nfor frame in frames:\n    img = cv2.imread(os.path.join(clip_path, frame))\n    out.write(img)\nout.release()\n\nprint(f\"✅ Input video saved: {video_path}\")\n\n# 2️⃣ Load trained YOLOv8 segmentation model\nmodel = YOLO(\"/kaggle/working/runs/segment/train7/weights/best.pt\")\n\n# 3️⃣ Run YOLOv8 on the video and force a custom save path\npredict_dir = \"/kaggle/working/yolo_predictions\"\nos.makedirs(predict_dir, exist_ok=True)\n\nresults = model.predict(\n    source=video_path,\n    save=True,\n    project=predict_dir,\n    name=\"lane_detect\",\n    imgsz=640\n)\n\n# 4️⃣ Locate processed video\npredicted_video_path = os.path.join(predict_dir, \"lane_detect\", \"sample_clip.mp4\")\n\nif not os.path.exists(predicted_video_path):\n    # Sometimes YOLO renames files — find the right one automatically\n    for file in os.listdir(os.path.join(predict_dir, \"lane_detect\")):\n        if file.endswith(\".mp4\"):\n            predicted_video_path = os.path.join(predict_dir, \"lane_detect\", file)\n            break\n\nprint(f\"🎥 Annotated video saved at: {predicted_video_path}\")\n\n# 5️⃣ Display processed video\nVideo(predicted_video_path, embed=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T11:10:33.738409Z","iopub.execute_input":"2025-09-06T11:10:33.738781Z","iopub.status.idle":"2025-09-06T11:10:38.014448Z","shell.execute_reply.started":"2025-09-06T11:10:33.738752Z","shell.execute_reply":"2025-09-06T11:10:38.013481Z"}},"outputs":[],"execution_count":null}]}